package org.onjava.housekeeping;// housekeeping/TerminationCondition.java
// (c)2021 MindView LLC: see Copyright.txt
// We make no guarantees that this code is fit for any purpose.
// Visit http://OnJava8.com for more book information.
// Using finalize() to detect an object that
// hasn't been properly cleaned up

/**
6.5　清理：终结和垃圾收集
程序员都知道初始化的重要性，但常常会忘记清理也同样重要。
毕竟，谁需要清理一个int呢？但用完一个对象后就弃之不顾，这样做可能并不安全。
当然，Java有垃圾收集器来回收不再使用的对象内存，但也有特殊情况：
假设你的对象在不使用new的情况下分配了一块“特殊”内存，而垃圾收集器只知道如何释放由new分配的内存，所以它不知道如何释放对象的这块“特殊”内存。
为了处理这种情况，Java允许在类中定义一个名为finalize()的方法。

finalize()方法的工作原理“应该”是这样的：当垃圾收集器准备释放对象占用的资源时，它首先调用finalize()方法，然后在下一次垃圾收集动作发生时，
才会真正回收这个对象占用的内存。因此如果使用了finalize()，就可以在垃圾收集时做一些重要的清理工作。

finalize()是一个潜在的编程陷阱，因为一些程序员，特别是C++程序员，刚开始可能会将它误认为C++中的析构函数，C++在销毁对象时必须调用这个函数。
在这里将C++和Java区分开来很重要，因为在C++中，（如果程序没有缺陷的话）对象一定会被销毁，而在Java中，对象并不总是被回收。或者换句话说：

你的对象可能不会被回收；
垃圾收集不是析构。
在你回收某个对象之前，如果要执行某些操作，那你得自己去做。Java没有析构函数或类似的概念，因此你必须创建一个普通方法来执行清理工作。
例如，假设某个对象在创建过程中会在屏幕上绘制自己，如果没有明确地从屏幕上将其擦除，它可能永远得不到清理。
如果在finalize()中加入了擦除功能，那么当对象被垃圾收集并调用finalize()时（并不能保证一定会发生），图像将先从屏幕上被擦除。
但如果这并没有发生，图像就会保留。

你也许会发现某个程序的对象存储空间一直没有被释放，这是因为这个程序在运行过程中，还没有耗尽存储空间。
如果直到程序执行结束，垃圾收集器也没有释放任何对象存储空间，那么在程序退出时这些存储空间会全部还给操作系统。
这个策略是恰当的，因为垃圾收集本身也有开销，如果没有做过垃圾收集，那就不用承担这部分开销了。

6.5.1　finalize()的作用
此时你应该已经明白，不能把finalize()当作一个通用的清理方法，那它到底有什么用呢？

这就和要记住的第三点有关了：

垃圾收集仅与内存有关。
也就是说，垃圾收集器存在的唯一原因就是回收程序里不再使用的内存。
所以任何与垃圾收集相关的动作（特别是finalize()方法），都必须同内存及其回收有关。

这是否意味着，如果一个对象里包含其他对象，这个对象就要在finalize()方法里显式释放这些对象？
不是这样的，垃圾收集器会释放所有对象的内存，而不管对象是如何创建的。
只有一种情况下可以使用finalize()：对象是以某种特殊方式（而非通过创建）分配的存储空间。但在Java中一切都是对象，这种情况怎么可能发生？

看起来之所以要有finalize()方法，是因为你可能没有使用Java中通用的方式来分配内存，而是采用了类似C语言的机制。
这主要通过本地方法来实现，本地方法可以在Java代码里调用非Java代码。
Java里的本地方法目前只支持C和C++，而C和C++又可以调用其他语言的代码，所以实际上Java可以调用任何代码。
在非Java代码里，可能会调用C的malloc()系列函数来分配存储空间，此时除非明确调用了free()方法，否则该存储空间不会被释放，这会导致内存泄漏。
free()是C和C++里的函数，所以需要在finalize()里通过本地方法来调用。

读到这里你可能觉得自己不会经常使用finalize()。4 的确是这样的，它并不适合做普通的清理工作。那普通的清理工作应该在哪里执行呢？

4Joshua Bloch在Effective Java Programming Language Guide一书的“Item 6: Avoid finalizers”一节中有更进一步的说明：“终结器是不可预测的，常常很危险，而且基本上是不必要的。”

6.5.2　你必须执行清理
要清理一个对象，用户必须在需要时调用相应的清理方法。这听起来很简单，但它与C++中析构函数的概念不太一样。在C++中，所有对象都会被销毁。
或者更确切地说，所有对象都应该被销毁。
如果C++对象是作为本地对象创建的（即在栈上创建——这在Java中是不可能的），则销毁发生在创建对象的作用域的右花括号处。
如果对象是使用new创建的（就像在Java中一样），那么当程序员调用C++操作符delete（在Java中不存在）时，析构函数会被调用。
如果C++程序员忘记调用delete，则析构函数不会被调用，这时就会出现内存泄漏，而且对象的其他部分也不会被清理。
这种错误很难追踪，这也是让程序员从C++迁移到Java的令人信服的原因之一。

相反，Java不允许创建本地对象，你必须始终使用new。在Java里没有用于释放对象的delete操作符，因为垃圾收集器会自动释放存储空间。
甚至可以简单地认为，由于有了垃圾收集，Java就不需要析构函数了。
然而随着学习的深入，你会发现垃圾收集器的存在并没有消除对析构函数的需求，或者完全代替它的作用（永远不要直接调用finalize()，这不是一个能接受的解决方案）。
除了内存释放之外，如果想要执行其他的清理工作，仍然需要在Java中显式调用适当的方法：这个方法相当于C++的析构函数，但没有那么方便。

记住，无论是垃圾收集还是终结操作，都不保证一定会发生。如果JVM没有面临内存耗尽的情况，它可能不会浪费时间去执行垃圾收集来恢复内存。

6.5.3　终止条件
通常情况下，我们不能依赖finalize()，而是必须创建单独的“清理”方法，并显式调用它们。
这样看起来，finalize()只对一些非常罕见的特殊场景的内存清理有用。不过finalize()还有一个有趣的用法，它不依赖于每次都被调用。这就是对象终止条件5的验证。

5Bill Venners在他和我一起举办的讲座中创造了这个术语。

当某个对象不再被使用时，也就是当它可以被清理时，该对象应该处于可以安全释放其内存的状态。
例如，假设某个对象代表一个打开的文件，那么在该对象被垃圾收集之前，程序员应该关闭这个文件。
如果该对象的任何部分没有被正确清理，程序中就会遗留难以发现的错误。
虽然finallize()方法无法保证一定会被调用，但它总归能发现问题——如果其中某个终结操作恰好揭示了隐藏的错误的话。
而能否发现问题才是我们真正关心的事情。

下面是一个使用它的简单示例：
使用finalize()来检查对象是否被正确清理
 */
import org.onjava.onjava.Nap;

class Book {
  boolean checkedOut = false;
  Book(boolean checkOut) {
    checkedOut = checkOut;
  }
  void checkIn() {
    checkedOut = false;
  }

  /**
   * 这个示例展示了@Override的使用。@表示注解，注解提供了代码的额外信息。
   * 这里它告诉编译器，你不是不小心重新定义了每个对象都有的finalize()方法——你知道自己在做什么。
   * 编译器会确保方法名字没有拼错，并且该方法确实存在于基类中。
   * 注解对读者来说也是一个提醒。
   * @Override是在Java 5中引入的，并在Java 7中进行了修改，本书中也一直在使用它。
   * 这里还使用了@SuppressWarnings("deprecation")注解，它可以禁止JDK 8以上的版本在编译时提示警告信息，
   * 因为在这些版本里finalize()已不再被正式支持。
   * 虽然你仍然可以使用它，但并不推荐（这相当于Java设计者承认了他们在引入finalize()时没有理解要解决的问题，
   * 从而在Java里错误地提供了finalize()方法。你会在本书中看到更多这样的情况）。
   * @throws Throwable
   */
  @SuppressWarnings("deprecation")
  @Override public void finalize() throws Throwable {
    if(checkedOut)
      System.out.println("Error: checked out");
    // Normally, you'll also do this:
//    应该总是假设finalize()的基类版本做了某些重要的工作，因此要使用super调用它，如同你在Book.finalize()中看到的那样。
     super.finalize(); // Call the base-class version
  }
}

public class TerminationCondition {
  public static void main(String[] args) {
    Book novel = new Book(true);
    // Proper cleanup:  正确清理：
    novel.checkIn();
    // Drop the reference, forget to clean up:  没有清理就丢掉了该对象的引用：
    new Book(true);
    // Force garbage collection & finalization: 强制垃圾收集和终结操作：
    //注意System.gc()用于强制进行终结操作。但即使不这么做，通过重复执行程序（假设程序会分配大量的内存而触发垃圾收集），也极有可能会发现错误的Book对象。
    System.gc();
    new Nap(1); // One second delay 延迟1秒
  }
}
/* Output:
Error: checked out
本例的终止条件要求所有的Book对象必须在被垃圾收集之前签入（check in），但main()方法里没有执行图书的签入操作。如果没有finalize()来验证终止条件，这里的错误很难被发现。
6.5.4　垃圾收集器的工作原理
很多编程语言在堆上分配对象的成本十分高昂，如果你以前用过这种语言，就可能很自然地认为Java在堆上分配所有数据（基本类型除外）的方案代价也很高。
然而，垃圾收集器可以显著提高对象创建的速度。
乍一听这可能有点奇怪——存储空间的释放会影响存储空间的分配——但这的确是一些Java虚拟机（JVM）的工作方式，这意味着，Java在堆上分配存储的速度，和其他语言在栈上分配存储的速度几乎一样快。

打个比方，你可以把C++的堆想象成一个院子，里面每个对象都有自己的地盘。一段时间以后，这个地盘可能会被废弃，需要重新使用。
在某些JVM中，Java的堆是不同的：它更像是一条传送带，每分配一个新对象，就向前移动一下。这意味着对象存储空间的分配速度非常快。
Java的“堆指针”只是简单地向前移动到尚未分配的区域，因此它的效率实际上与C++的栈分配差不多。
当然记录分配情况的簿记工作也会有一些额外的开销，但这和查找可用存储空间的开销不可相提并论。

你也许已经意识到，堆实际上不是传送带，要是真那样的话，肯定会导致频繁的内存分页调度（paging）——通过将数据移入移出磁盘，让内存看起来比实际的多。
分页调度会显著影响性能，最终，在创建了足够多的对象后，内存资源会被耗尽。这里的关键就在于垃圾收集器的介入。
在回收垃圾的同时，垃圾收集器还会压缩堆中的所有对象，这样就可以很方便地将“堆指针”移到靠近传送带起点的位置，从而尽量避免缺页错误（page fault）。
垃圾收集器在分配存储空间的同时会将对象重新排列，由此实现一个高速的、有无限空闲空间的堆模型。

了解其他系统中垃圾收集的工作方式，可以让我们更好地理解Java中的垃圾收集。引用计数（reference counting）是一种简单但速度很慢的垃圾收集技术。
在这个垃圾收集方案里，每个对象都包含一个引用计数器，并且每次该对象被引用时，引用计数都会增加。每次引用离开作用域或设置为null时，引用计数都会减少。
虽然管理引用计数的开销不大，但它在程序的整个生命周期中都会持续存在。
垃圾收集器会遍历整个对象列表，当找到引用计数为零的对象时，就释放该对象占用的存储空间（不过引用计数方案通常会在计数变为零时立即释放对象）。
引用计数的一个缺点是，如果对象彼此之间循环引用，就算变成了垃圾，它们的引用计数可能仍不是零。定位这种自引用的对象组需要垃圾收集器做大量额外的工作。
引用计数通常用于解释垃圾收集的工作方式，但它似乎并没有出现在任何JVM实现中。

一些更快的方案并不使用引用计数，而是基于这样一个想法：对于任何没有被废弃的对象，最终都能追溯到它存活在栈或静态存储区中的引用。
这个引用链可能会穿过多个对象层次。因此，如果从栈和静态存储区开始遍历所有引用，就能找到所有存活的对象。
对找到的每个引用，还要跟踪它指向的对象，然后跟踪那个对象中的所有引用，依次反复进行，直到找到了源于这个（位于栈或静态存储区的）引用的所有对象。
在这个过程中遍历的每个对象都必须是“活”的。注意，这样的话，废弃的自引用对象组就不会产生问题了——它们根本不会被找到，因此自动成为垃圾。

在这种方式下，JVM使用了一种自适应的垃圾收集方案，至于如何处理找到的存活对象，则取决于当前使用的垃圾收集算法。
其中一种算法是“停止-复制”（stop-and-copy）。这意味程序首先停止（所以它不属于后台收集模式），原因很明显。
然后，将所有的存活对象从当前堆复制到另一个堆，剩下的就都是垃圾。
另外，当对象被复制到新堆时，它们会被紧挨着打包，因此新堆十分紧凑（并且允许我们像前面描述的那样，将新堆尾部空出来，从头开始分配存储空间）。

当对象从一个地方移动到另一个地方时，所有指向该对象的引用都必须修改。
从栈或静态存储区到对象这个链条上遍历出的引用可以立即更改，但在遍历过程中可能会有新出现的指向此对象的其他引用。
这些引用在找到时就会被修复（想象一张将旧地址映射到新地址的表）。

这些所谓的“复制收集器”效率比较低，因为它们存在两个问题。
第一个问题是，先得有两个堆，然后在这两个独立的堆之间来回复制对象，这比实际需要的内存多了一倍。
一些JVM解决这个问题的方式是，按需要将堆划分成块，复制动作发生在块之间。

第二个问题是复制过程本身。一旦程序变得稳定，它可能就会很少产生垃圾，甚至没有。
尽管如此，复制收集器仍会将所有内存从一个地方复制到另一个地方，这是一种浪费。
为了防止这种情况，一些JVM检测到没有新垃圾产生后，会切换到不同的垃圾收集算法（这就是“自适应”）。
这种垃圾收集算法叫“标记-清除”（mark-and-sweep），Sun公司JVM的早期版本一直在使用这个算法。
对于一般用途，“标记-清除”算法相当慢，但是在垃圾很少或没有的时候，它的速度就很快了。

“标记-清除”算法遵循相同的逻辑，即从栈和静态存储区开始，遍历所有的引用，进而找出所有存活的对象。
每当它找到一个存活对象，就会给该对象设置一个标志——此时尚未开始收集。只有在标记过程完成后才会进行清除。
在清除过程中，没有标记的对象会被回收，而不会发生任何复制动作。因此如果收集器想压缩堆里的碎片，就需要重新整理剩余的对象。

“停止-复制”指的是这种类型的垃圾收集不是在后台完成的；相反，程序会在垃圾收集发生时停止。
在Oracle的文献里，许多资料将垃圾收集描述为低优先级的后台进程，但早期版本的JVM并没有以这种方式实现垃圾收集。
相反，这些垃圾收集器在内存不足时会停止程序。同样，“标记-清除”算法也会在垃圾收集过程中暂停程序。

如前文所述，这里所描述的JVM，分配内存时是以较大的块（block）为单位。如果对象较大，它会占用单独的块。
严格来说，“停止-复制”要求所有存活对象都从旧堆复制到新堆，然后才能释放旧堆，这意味着需要大量的内存。
有了块之后，垃圾收集器就可以将对象直接复制到废弃的块里。每个块都有一个代数（generation count）来跟踪它是否还活着。
通常，只压缩自上次垃圾收集以来创建的块。如果块在某处被引用，它的代数就会增加。
这种方式可以很方便地处理大量短期临时对象，而这也是正常情况下最常遇到的。
垃圾收集器会周期性地进行全面清理——不过大对象仍然不会被复制（只是增加它们的代数），而含有小对象的块则会被复制和压缩。
JVM会监控垃圾收集的效率，如果所有对象都很稳定，垃圾收集器效率很低的话，它会切换到“标记-清除”算法。
同样，JVM会跟踪标记和清除的效果，如果堆里开始出现很多碎片，它会切换回“停止-复制”算法。
这就是“自适应”部分的用武之地，因此我们才会得到这么个啰唆的称呼：“自适应的、分代的、停止-复制、标记-清除”垃圾收集器。

JVM中有许多附加技术可以提升速度。其中特别重要的一项就是“即时（just-in-time, JIT）编译器”，它与加载器的操作有关。
即时编译器会将程序部分或全部编译为本地机器码，这样就不需要JVM的解释，从而运行得更快。
当需要加载一个类时（通常是第一次创建该类的对象时），会先定位.class文件，然后将该类的字节码加载到内存中。
这时候可以简单地让即时编译器编译所有代码，但这样做有两个缺点：编译代码需要更多的时间，而这个时间会在程序的整个生命周期中累积起来；
另外就是增加了可执行文件的大小（字节码比扩展的JIT代码要紧凑得多），这可能会导致分页，从而减缓程序的运行速度。
另一种方法是惰性评估（lazy evaluation），这意味着除非必要，否则不会对代码进行即时编译。
因此，永远不会执行的代码可能压根儿就不会被即时编译。
新版JDK中的Java HotSpot技术就采用了类似的方法，每次执行时都会通过即时编译器优化部分代码，因此代码执行的次数越多，速度就越快。
*/
